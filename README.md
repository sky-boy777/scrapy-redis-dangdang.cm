# scrapy-redis-dangdang.cm
scrapy-redis分布式爬虫，爬取当当网图书信息

前期的准备
虚拟机下乌班图下redis：url去重，持久化
mongodb：保存数据
PyCharm：写代码
谷歌浏览器：分析要提取的数据
爬取图书每个分类下的小分类下的图书信息（分类标题，小分类标题，图书标题，作者，图书简介，价格，电子书价格，出版社，封面，图书链接）
思路：按每个大分类分组，再按小分类分组，再按每本书分组，最后提取数据
